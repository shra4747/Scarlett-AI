{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shravanprasanth/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from paddleocr import PaddleOCR # type: ignore\n",
    "import logging\n",
    "from lime_enhancement import LIME\n",
    "from scipy.ndimage import rotate\n",
    "from weighted_levenshtein import lev\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\n",
      "Found existing installation: opencv-contrib-python 4.10.0.84\n",
      "Uninstalling opencv-contrib-python-4.10.0.84:\n",
      "  Successfully uninstalled opencv-contrib-python-4.10.0.84\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_12_0_x86_64.whl (66.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/shravanprasanth/Library/Python/3.9/lib/python/site-packages (from opencv-contrib-python) (1.26.4)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "paddleocr 2.9.1 requires opencv-python, which is not installed.\u001b[0m\n",
      "Successfully installed opencv-contrib-python-4.10.0.84\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall opencv-python -y\n",
    "!pip3 uninstall opencv-contrib-python -y\n",
    "!pip3 install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /Users/shravanprasanth/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3910/3910 [00:15<00:00, 256.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /Users/shravanprasanth/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:20<00:00, 496.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /Users/shravanprasanth/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2138/2138 [00:17<00:00, 124.90it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "upscale_model = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "upscale_model.readModel('/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/models/ESPCN_x4.pb')\n",
    "upscale_model.setModel('espcn', 4)\n",
    "\n",
    "model = YOLO('/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/models/y11v9.pt')\n",
    "logging.getLogger('ultralytics').setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True,gpu_mem=1000, show_log=False)\n",
    "\n",
    "original_red_team_numbers = [\"75\", \"2722\", \"1391\"]\n",
    "original_blue_team_numbers = [\"56\", \"5401\", \"8513\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_red_team_numbers = [\"75\", \"2722\", \"1391\"]\n",
    "original_blue_team_numbers = [\"56\", \"5401\", \"8513\"]\n",
    "substitute_costs = np.ones((128, 128), dtype=np.float64)  # make a 2D array of 1's\n",
    "\n",
    "similarities = [\n",
    "    (\"S\", \"5\"),\n",
    "    (\"A\", \"4\"),\n",
    "    (\"D\", \"0\"),\n",
    "    (\"I\", \"1\"),\n",
    "    (\"O\", \"0\"),\n",
    "    (\"R\", \"6\"),\n",
    "    (\"n\", \"0\"),\n",
    "    (\"7\", \"1\"),\n",
    "    (\"T\", \"7\"),\n",
    "    (\"B\", \"5\"),\n",
    "    (\"S\", \"2\"),\n",
    "    (\"Q\", \"0\"),\n",
    "]\n",
    "\n",
    "for similarity1, similarity2 in similarities:\n",
    "    substitute_costs[ord(similarity1), ord(similarity2)] = 0.5  \n",
    "    substitute_costs[ord(similarity2), ord(similarity1)] = 0.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/videos/dcmp58-auto.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/videos/output/dcmp58-auto-ilt.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Could not open video.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "video_path = \"/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/videos/dcmp58-auto.mp4\"\n",
    "output_path = \"/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/videos/output/dcmp58-auto-ilt.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "bounding_box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "frame_count = 0\n",
    "lime = LIME(iterations=1, alpha=1.5, rho=1.5, gamma=0.5, strategy=1)\n",
    "\n",
    "previousRedBoxes = {}\n",
    "previousBlueBoxes = {}\n",
    "\n",
    "\n",
    "def sort_boxes_by_distance(previousBoxes, curr_centroid_x, curr_centroid_y):\n",
    "    def calculate_distance(box):\n",
    "        prev_centroid_x = (box[\"x1\"] + box[\"x2\"]) / 2\n",
    "        prev_centroid_y = (box[\"y1\"] + box[\"y2\"]) / 2\n",
    "        distance = sqrt((curr_centroid_x - prev_centroid_x) ** 2 + (curr_centroid_y - prev_centroid_y) ** 2)\n",
    "        return distance\n",
    "\n",
    "    sorted_boxes = sorted(previousBoxes.values(), key=calculate_distance)\n",
    "    return sorted_boxes\n",
    "\n",
    "\n",
    "with tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT))) as pbar:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Finished processing all frames.\")\n",
    "            break\n",
    "\n",
    "        if frame is None:\n",
    "            print(\"Empty frame encountered.\")\n",
    "            continue\n",
    "\n",
    "        # Convert the frame from BGR (OpenCV) to RGB (PIL)\n",
    "        image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        results = model(image_pil)\n",
    "\n",
    "\n",
    "        blue_boxes = []\n",
    "        red_boxes = []\n",
    "\n",
    "        red_team_numbers = original_red_team_numbers.copy()\n",
    "        blue_team_numbers = original_blue_team_numbers.copy()\n",
    "        \n",
    "        # Separate boxes by team color\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            boxes = sorted(boxes, key=lambda box: box.conf, reverse=True)\n",
    "            ocr_count = 0\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                start_row = (y1 + y2) // 2\n",
    "                bottom_half = frame[start_row:y2, x1:x2]\n",
    "\n",
    "                # Calculate average RGB to determine the team color\n",
    "                average_rgb = np.mean(bottom_half, axis=(0, 1))\n",
    "                label = 'Blue' if average_rgb[0] > average_rgb[2] else 'Red'\n",
    "                color = (255, 0, 0) if label == 'Blue' else (0, 0, 255)\n",
    "\n",
    "                centroid_x = (x1 + x2) / 2\n",
    "                centroid_y = (y1 + y2) / 2\n",
    "                red_sorted_boxes = sort_boxes_by_distance(previousRedBoxes, centroid_x, centroid_y)\n",
    "                blue_sorted_boxes = sort_boxes_by_distance(previousBlueBoxes, centroid_x, centroid_y)\n",
    "                \n",
    "                if len(red_sorted_boxes) != 0 and len(blue_sorted_boxes) != 0:\n",
    "                    red_centroid_x = (red_sorted_boxes[0]['x1'] + red_sorted_boxes[0]['x2']) / 2\n",
    "                    red_centroid_y = (red_sorted_boxes[0]['y1'] + red_sorted_boxes[0]['y2']) / 2\n",
    "                    blue_centroid_x = (blue_sorted_boxes[0]['x1'] + blue_sorted_boxes[0]['x2']) / 2\n",
    "                    blue_centroid_y = (blue_sorted_boxes[0]['y1'] + blue_sorted_boxes[0]['y2']) / 2\n",
    "\n",
    "                    red_distance = sqrt((centroid_x - red_centroid_x) ** 2 + (centroid_y - red_centroid_y) ** 2)\n",
    "                    blue_distance = sqrt((centroid_x - blue_centroid_x) ** 2 + (centroid_y - blue_centroid_y) ** 2)\n",
    "\n",
    "                    if label == \"Blue\":\n",
    "                        if red_distance < blue_distance:\n",
    "                            label = \"Red\"\n",
    "                            color = (0,0,255)\n",
    "                        \n",
    "                    if label == \"Red\":\n",
    "                        if blue_distance < red_distance:\n",
    "                            label = \"Blue\"\n",
    "                            color = (255,0,0)\n",
    "\n",
    "\n",
    "                # OCR: Recognize text in the bottom half of the box\n",
    "                height, width, _ = bottom_half.shape\n",
    "                upscaled_bottom_half = upscale_model.upsample(bottom_half)\n",
    "                gray = cv2.cvtColor(upscaled_bottom_half, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Apply LIME enhancement\n",
    "                lime.load(gray)\n",
    "                enhanced_image = lime.enhance()\n",
    "\n",
    "                result = ocr.ocr(np.array(enhanced_image), cls=True)\n",
    "                ocr_result = \"\"\n",
    "                try:\n",
    "                    ocr_result = result[0][0][1][0]\n",
    "                except:\n",
    "                    enhanced_image = rotate(enhanced_image, -20)\n",
    "                    result = ocr.ocr(np.array(enhanced_image), cls=True)\n",
    "                    try:\n",
    "                        ocr_result = result[0][0][1][0]\n",
    "                    except:\n",
    "                        enhanced_image = rotate(enhanced_image, 40)\n",
    "                        result = ocr.ocr(np.array(enhanced_image), cls=True)\n",
    "                        try:\n",
    "                            ocr_result = result[0][0][1][0]\n",
    "                        except:\n",
    "                            ocr_result = \"\"\n",
    "                \n",
    "\n",
    "                detected_text = ocr_result.replace(\" \", \"\") if ocr_result else \"\"\n",
    "                if detected_text != \"\":\n",
    "                    ocr_count += 1\n",
    "                \n",
    "                if label == 'Blue':\n",
    "                    blue_boxes.append((x1, y1, x2, y2, detected_text, color))\n",
    "                else:\n",
    "                    red_boxes.append((x1, y1, x2, y2, detected_text, color))\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        def assign_prev_boxes(alliance: str, box: dict):\n",
    "            global previousBlueBoxes\n",
    "            global previousRedBoxes\n",
    "\n",
    "            if alliance.lower() == \"red\":\n",
    "                previousRedBoxes[box['closest_robot_match']] = box\n",
    "            else:\n",
    "                previousBlueBoxes[box['closest_robot_match']] = box\n",
    "            \n",
    "        \n",
    "        \n",
    "        def assign_team_numbers(alliance:str, boxes:list):\n",
    "\n",
    "            if alliance.lower() == \"red\":\n",
    "                available_team_numbers = original_red_team_numbers.copy()\n",
    "                # numbers = original_red_team_numbers.copy()\n",
    "                previousBoxes = previousRedBoxes\n",
    "            else:\n",
    "                available_team_numbers = original_blue_team_numbers.copy()\n",
    "                # numbers = original_blue_team_numbers.copy()\n",
    "                previousBoxes = previousBlueBoxes\n",
    "\n",
    "            for x1, y1, x2, y2, detected_text, color in boxes:          \n",
    "                distances = {num: lev(detected_text, num, substitute_costs=substitute_costs) for num in available_team_numbers}\n",
    "                sorted_distances = sorted(distances.items(), key=lambda item: item[1])\n",
    "                \n",
    "                closest_robot_match = sorted_distances[0][0]\n",
    "                closest_robot_match_distance = sorted_distances[0][1]\n",
    "\n",
    "                curr_centroid_x = (x1 + x2) / 2\n",
    "                curr_centroid_y = (y1 + y2) / 2\n",
    "\n",
    "\n",
    "                curr_robot_dict = {\n",
    "                            \"x1\": x1,\n",
    "                            \"y1\": y1,\n",
    "                            \"x2\": x2,\n",
    "                            \"y2\": y2,\n",
    "                            \"detected_text\": detected_text,\n",
    "                            \"color\": color,\n",
    "                            \"closest_robot_match\": closest_robot_match, \n",
    "                            \"closest_robot_match_distance\": closest_robot_match_distance\n",
    "                        }\n",
    "                \n",
    "                if len(previousBoxes) != 3:\n",
    "                    assign_prev_boxes(alliance, curr_robot_dict)\n",
    "                else:\n",
    "                    sorted_boxes = sort_boxes_by_distance(previousBoxes, curr_centroid_x, curr_centroid_y)\n",
    "                    closest_prev_box_by_distance = sorted_boxes[0]\n",
    "                    \n",
    "                    if closest_prev_box_by_distance[\"closest_robot_match_distance\"] < closest_robot_match_distance:\n",
    "                        curr_robot_dict = {\n",
    "                            \"x1\": x1,\n",
    "                            \"y1\": y1,\n",
    "                            \"x2\": x2,\n",
    "                            \"y2\": y2,\n",
    "                            \"detected_text\": closest_prev_box_by_distance[\"detected_text\"],\n",
    "                            \"color\": closest_prev_box_by_distance[\"color\"],\n",
    "                            \"closest_robot_match\": closest_prev_box_by_distance[\"closest_robot_match\"], \n",
    "                            \"closest_robot_match_distance\": closest_prev_box_by_distance[\"closest_robot_match_distance\"]\n",
    "                        }\n",
    "                        assign_prev_boxes(alliance, curr_robot_dict)\n",
    "                    else:\n",
    "                        assign_prev_boxes(alliance, curr_robot_dict)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), curr_robot_dict['color'], 2)\n",
    "                cv2.putText(frame, f\"{curr_robot_dict['closest_robot_match']}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, curr_robot_dict['color'], 2)\n",
    "        \n",
    "        # Assign team numbers to Blue and Red boxes\n",
    "        assign_team_numbers(alliance=\"red\", boxes=red_boxes)\n",
    "        assign_team_numbers(alliance=\"blue\", boxes=blue_boxes)\n",
    "        # Write the frame with annotations to the output video\n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    # break\n",
    "        \n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video processing complete. Output saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= [1,2,3]\n",
    "x.pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
