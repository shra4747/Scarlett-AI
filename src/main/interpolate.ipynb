{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T03:03:49.979004Z",
     "iopub.status.busy": "2024-08-19T03:03:49.978483Z",
     "iopub.status.idle": "2024-08-19T03:03:57.166765Z",
     "shell.execute_reply": "2024-08-19T03:03:57.165385Z",
     "shell.execute_reply.started": "2024-08-19T03:03:49.978975Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install ultralytics easyocr rapidfuzz supervision levenshtein\n",
    "!pip3 uninstall opencv-python -y\n",
    "!pip3 uninstall opencv-contrib-python -y\n",
    "!pip3 install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-18T02:19:23.814227Z",
     "iopub.status.busy": "2024-08-18T02:19:23.813898Z",
     "iopub.status.idle": "2024-08-18T02:21:54.940802Z",
     "shell.execute_reply": "2024-08-18T02:21:54.939780Z",
     "shell.execute_reply.started": "2024-08-18T02:19:23.814223Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install paddlepaddle-gpu \"paddleocr>=2.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T03:09:09.154094Z",
     "iopub.status.busy": "2024-08-19T03:09:09.153274Z",
     "iopub.status.idle": "2024-08-19T03:09:16.553083Z",
     "shell.execute_reply": "2024-08-19T03:09:16.551911Z",
     "shell.execute_reply.started": "2024-08-19T03:09:09.154060Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "from rapidfuzz.distance import JaroWinkler\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from paddleocr import PaddleOCR\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T03:09:19.305612Z",
     "iopub.status.busy": "2024-08-19T03:09:19.304611Z",
     "iopub.status.idle": "2024-08-19T03:09:19.311322Z",
     "shell.execute_reply": "2024-08-19T03:09:19.310162Z",
     "shell.execute_reply.started": "2024-08-19T03:09:19.305578Z"
    }
   },
   "outputs": [],
   "source": [
    "upscale_model = cv2.dnn_superres.DnnSuperResImpl_create()\n",
    "upscale_model.readModel('/notebooks/models/ESPCN_x4.pb')\n",
    "upscale_model.setModel('espcn', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T03:09:20.459495Z",
     "iopub.status.busy": "2024-08-19T03:09:20.458908Z",
     "iopub.status.idle": "2024-08-19T03:09:25.665364Z",
     "shell.execute_reply": "2024-08-19T03:09:25.664446Z",
     "shell.execute_reply.started": "2024-08-19T03:09:20.459450Z"
    }
   },
   "outputs": [],
   "source": [
    "model = YOLO('/notebooks/models/y8v7.pt')\n",
    "logging.getLogger('ultralytics').setLevel(logging.CRITICAL)\n",
    "# Initialize EasyOCR reader\n",
    "# reader = easyocr.Reader(['en'], gpu=True)\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True,gpu_mem=1000, show_log=False)\n",
    "# Define the team numbers for red and blue teams\n",
    "original_red_team_numbers = [\"75\", \"2722\", \"1391\"]  # Replace with actual red team numbers\n",
    "original_blue_team_numbers = [\"56\", \"5401\", \"8513\"]  # Replace with actual blue team numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T03:10:23.394579Z",
     "iopub.status.busy": "2024-08-19T03:10:23.393941Z",
     "iopub.status.idle": "2024-08-19T03:10:23.410615Z",
     "shell.execute_reply": "2024-08-19T03:10:23.409786Z",
     "shell.execute_reply.started": "2024-08-19T03:10:23.394551Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import fft\n",
    "from skimage import io, exposure, img_as_ubyte, img_as_float\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "def firstOrderDerivative(n, k=1):\n",
    "    return np.eye(n) * (-1) + np.eye(n, k=k)\n",
    "\n",
    "\n",
    "def toeplitizMatrix(n, row):\n",
    "    vecDD = np.zeros(n)\n",
    "    vecDD[0] = 4\n",
    "    vecDD[1] = -1\n",
    "    vecDD[row] = -1\n",
    "    vecDD[-1] = -1\n",
    "    vecDD[-row] = -1\n",
    "    return vecDD\n",
    "\n",
    "\n",
    "def vectorize(matrix):\n",
    "    return matrix.T.ravel()\n",
    "\n",
    "\n",
    "def reshape(vector, row, col):\n",
    "    return vector.reshape((row, col), order='F')\n",
    "\n",
    "\n",
    "class LIME:\n",
    "    def __init__(self, iterations=10, alpha=2, rho=2, gamma=0.7, strategy=2, *args, **kwargs):\n",
    "        self.iterations = iterations\n",
    "        self.alpha = alpha\n",
    "        self.rho = rho\n",
    "        self.gamma = gamma\n",
    "        self.strategy = strategy\n",
    "\n",
    "    def load(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # Convert the image to float if it's not already\n",
    "            if img.dtype != np.float32 and img.dtype != np.float64:\n",
    "                img = img_as_float(img)\n",
    "            self.L = img\n",
    "        else:\n",
    "            raise ValueError(\"Input must be a numpy.ndarray\")\n",
    "\n",
    "        self.row = self.L.shape[0]\n",
    "        self.col = self.L.shape[1]\n",
    "\n",
    "        # Handle grayscale images (2D arrays) separately\n",
    "        if self.L.ndim == 2:\n",
    "            self.T_hat = self.L\n",
    "        else:\n",
    "            self.T_hat = np.max(self.L, axis=2)\n",
    "\n",
    "        self.dv = firstOrderDerivative(self.row)\n",
    "        self.dh = firstOrderDerivative(self.col, -1)\n",
    "        self.vecDD = toeplitizMatrix(self.row * self.col, self.row)\n",
    "        self.W = self.weightingStrategy()\n",
    "\n",
    "    def weightingStrategy(self):\n",
    "        if self.strategy == 2:\n",
    "            dTv = self.dv @ self.T_hat\n",
    "            dTh = self.T_hat @ self.dh\n",
    "            Wv = 1 / (np.abs(dTv) + 1)\n",
    "            Wh = 1 / (np.abs(dTh) + 1)\n",
    "            return np.vstack([Wv, Wh])\n",
    "        else:\n",
    "            return np.ones((self.row * 2, self.col))\n",
    "\n",
    "    def __T_subproblem(self, G, Z, u):\n",
    "        X = G - Z / u\n",
    "        Xv = X[:self.row, :]\n",
    "        Xh = X[self.row:, :]\n",
    "        temp = self.dv @ Xv + Xh @ self.dh\n",
    "        numerator = fft.fft(vectorize(2 * self.T_hat + u * temp))\n",
    "        denominator = fft.fft(self.vecDD * u) + 2\n",
    "        T = fft.ifft(numerator / denominator)\n",
    "        T = np.real(reshape(T, self.row, self.col))\n",
    "        return exposure.rescale_intensity(T, (0, 1), (0.001, 1))\n",
    "\n",
    "    def __G_subproblem(self, T, Z, u, W):\n",
    "        dT = self.__derivative(T)\n",
    "        epsilon = self.alpha * W / u\n",
    "        X = dT + Z / u\n",
    "        return np.sign(X) * np.maximum(np.abs(X) - epsilon, 0)\n",
    "\n",
    "    def __Z_subproblem(self, T, G, Z, u):\n",
    "        dT = self.__derivative(T)\n",
    "        return Z + u * (dT - G)\n",
    "\n",
    "    def __u_subproblem(self, u):\n",
    "        return u * self.rho\n",
    "\n",
    "    def __derivative(self, matrix):\n",
    "        v = self.dv @ matrix\n",
    "        h = matrix @ self.dh\n",
    "        return np.vstack([v, h])\n",
    "\n",
    "    def illumMap(self):\n",
    "        T = np.zeros((self.row, self.col))\n",
    "        G = np.zeros((self.row * 2, self.col))\n",
    "        Z = np.zeros((self.row * 2, self.col))\n",
    "        u = 1\n",
    "\n",
    "        for _ in range(0, self.iterations):\n",
    "            T = self.__T_subproblem(G, Z, u)\n",
    "            G = self.__G_subproblem(T, Z, u, self.W)\n",
    "            Z = self.__Z_subproblem(T, G, Z, u)\n",
    "            u = self.__u_subproblem(u)\n",
    "\n",
    "        return T ** self.gamma\n",
    "\n",
    "    def enhance(self):\n",
    "        self.T = self.illumMap()\n",
    "\n",
    "        if self.L.ndim == 2:  # Grayscale image\n",
    "            self.R = self.L / self.T  # Direct division\n",
    "        else:  # Color image\n",
    "            self.R = self.L / np.repeat(self.T[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "        self.R = exposure.rescale_intensity(self.R, (0, 1))\n",
    "        self.R = img_as_ubyte(self.R)\n",
    "        return self.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-19T03:15:51.087913Z",
     "iopub.status.busy": "2024-08-19T03:15:51.087123Z",
     "iopub.status.idle": "2024-08-19T03:16:22.635490Z",
     "shell.execute_reply": "2024-08-19T03:16:22.634362Z",
     "shell.execute_reply.started": "2024-08-19T03:15:51.087879Z"
    }
   },
   "outputs": [],
   "source": [
    "video_path = \"/notebooks/videos/dcmp58-3sec.mp4\"\n",
    "output_path = \"/notebooks/videos/dcmp58-3sec-lime.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "bounding_box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "frame_count = 0\n",
    "lime = LIME(iterations=1, alpha=1.5, rho=1.5, gamma=0.5, strategy=1)\n",
    "\n",
    "with tqdm(total=52) as pbar:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        red_team_numbers = original_red_team_numbers.copy()\n",
    "        blue_team_numbers = original_blue_team_numbers.copy()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Finished processing all frames.\")\n",
    "            break\n",
    "\n",
    "        if frame is None:\n",
    "            print(\"Empty frame encountered.\")\n",
    "            continue\n",
    "\n",
    "        # Convert the frame from BGR (OpenCV) to RGB (PIL)\n",
    "        image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        results = model(image_pil)\n",
    "\n",
    "        blue_boxes = []\n",
    "        red_boxes = []\n",
    "\n",
    "        # Separate boxes by team color\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                start_row = (y1 + y2) // 2\n",
    "                bottom_half = frame[start_row:y2, x1:x2]\n",
    "\n",
    "                # Calculate average RGB to determine the team color\n",
    "                average_rgb = np.mean(bottom_half, axis=(0, 1))\n",
    "                label = 'Blue' if average_rgb[0] > average_rgb[2] else 'Red'\n",
    "                color = (255, 0, 0) if label == 'Blue' else (0, 0, 255)\n",
    "\n",
    "                # OCR: Recognize text in the bottom half of the box\n",
    "                height, width, _ = bottom_half.shape\n",
    "                upscaled_bottom_half = upscale_model.upsample(bottom_half)\n",
    "                gray = cv2.cvtColor(upscaled_bottom_half, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Apply LIME enhancement\n",
    "                lime.load(gray)\n",
    "                enhanced_image = lime.enhance()\n",
    "\n",
    "                result = ocr.ocr(np.array(enhanced_image), cls=True)\n",
    "                ocr_result = \"\"\n",
    "                try:\n",
    "                    ocr_result = result[0][0][1][0]\n",
    "                except:\n",
    "                    ocr_result = \"\"\n",
    "\n",
    "                detected_text = ocr_result.replace(\" \", \"\") if ocr_result else \"\"\n",
    "\n",
    "                if label == 'Blue':\n",
    "                    blue_boxes.append((x1, y1, x2, y2, detected_text, color))\n",
    "                else:\n",
    "                    red_boxes.append((x1, y1, x2, y2, detected_text, color))\n",
    "\n",
    "        def assign_team_numbers(boxes, team_numbers, previous_assignments=None):\n",
    "            # Create a copy of the team numbers to avoid modifying the original list\n",
    "            available_team_numbers = team_numbers[:]\n",
    "            assigned_numbers = set()  # Track used numbers in this frame\n",
    "\n",
    "            # Create a mapping of detected boxes to team numbers\n",
    "            box_to_team_mapping = {}\n",
    "\n",
    "            for x1, y1, x2, y2, detected_text, color in boxes:\n",
    "                if detected_text:\n",
    "                    # Calculate Levenshtein distances\n",
    "                    distances = {num: levenshtein_distance(detected_text, num) for num in available_team_numbers}\n",
    "                    # Sort distances by closest match\n",
    "                    sorted_distances = sorted(distances.items(), key=lambda item: item[1])\n",
    "\n",
    "                    detected_team_number = None\n",
    "                    for team_number, _ in sorted_distances:\n",
    "                        if team_number not in assigned_numbers:\n",
    "                            detected_team_number = team_number\n",
    "                            assigned_numbers.add(team_number)\n",
    "                            available_team_numbers.remove(team_number)\n",
    "                            break\n",
    "\n",
    "                    # If no match found, fallback to the first available number\n",
    "                    if detected_team_number is None and available_team_numbers:\n",
    "                        detected_team_number = available_team_numbers.pop(0)\n",
    "                        assigned_numbers.add(detected_team_number)\n",
    "                else:\n",
    "                    # Handle cases with no detected text\n",
    "                    if available_team_numbers:\n",
    "                        detected_team_number = available_team_numbers.pop(0)\n",
    "                        assigned_numbers.add(detected_team_number)\n",
    "                    else:\n",
    "                        detected_team_number = \"Unknown\"  # Fallback if all numbers are used (should not happen with correct data)\n",
    "\n",
    "                # Map the box to the detected team number\n",
    "                box_to_team_mapping[(x1, y1, x2, y2)] = detected_team_number\n",
    "\n",
    "            # If you have previous frame assignments, you can interpolate to handle missing data\n",
    "            if previous_assignments:\n",
    "                for box in box_to_team_mapping:\n",
    "                    if box_to_team_mapping[box] == \"Unknown\":\n",
    "                        # Attempt to interpolate from previous frame's data\n",
    "                        box_to_team_mapping[box] = previous_assignments.get(box, \"Unknown\")\n",
    "\n",
    "            # Draw the bounding boxes and labels on the image\n",
    "            for (x1, y1, x2, y2), detected_team_number in box_to_team_mapping.items():\n",
    "                # Draw the bounding box and label on the image\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, f\"{detected_team_number}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "            return box_to_team_mapping  # Return mapping for potential interpolation in next frame\n",
    "        \n",
    "        \n",
    "        # Assign team numbers to Blue and Red boxes\n",
    "        assign_team_numbers(blue_boxes, blue_team_numbers)\n",
    "        assign_team_numbers(red_boxes, red_team_numbers)\n",
    "\n",
    "        # Write the frame with annotations to the output video\n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "        \n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video processing complete. Output saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
