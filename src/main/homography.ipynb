{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerialKeyPoints = { ## 2D\n",
    "    'imageSize': {'width': 1530, 'height': 778},\n",
    "    'keyPoints': [\n",
    "        {\"id\": \"new-point-29\", \"x\": 63, \"y\": 41},\n",
    "        {\"id\": \"new-point-5\", \"x\": 558, \"y\": 41},\n",
    "        {\"id\": \"new-point-8\", \"x\": 764, \"y\": 41},\n",
    "        {\"id\": \"new-point-12\", \"x\": 970, \"y\": 41},\n",
    "        {\"id\": \"new-point-35\", \"x\": 1467, \"y\": 41},\n",
    "        {\"id\": \"new-point-33\", \"x\": 1467, \"y\": 645},\n",
    "        {\"id\": \"new-point-52\", \"x\": 1387, \"y\": 692},\n",
    "        {\"id\": \"new-point-53\", \"x\": 1311, \"y\": 738},\n",
    "        {\"id\": \"new-point-40\", \"x\": 970, \"y\": 738},\n",
    "        {\"id\": \"new-point-9\", \"x\": 765, \"y\": 738},\n",
    "        {\"id\": \"new-point-42\", \"x\": 558, \"y\": 738},\n",
    "        {\"id\": \"new-point-51\", \"x\": 217, \"y\": 738},\n",
    "        {\"id\": \"new-point-30\", \"x\": 141, \"y\": 692},\n",
    "        {\"id\": \"new-point-31\", \"x\": 63, \"y\": 645},\n",
    "        {\"id\": \"new-point-44\", \"x\": 532, \"y\": 260},\n",
    "        {\"id\": \"new-point-43\", \"x\": 332, \"y\": 388},\n",
    "        {\"id\": \"new-point-46\", \"x\": 532, \"y\": 516},\n",
    "        {\"id\": \"new-point-48\", \"x\": 996, \"y\": 260},\n",
    "        {\"id\": \"new-point-47\", \"x\": 1197, \"y\": 388},\n",
    "        {\"id\": \"new-point-49\", \"x\": 996, \"y\": 516},\n",
    "    ]\n",
    "}\n",
    "\n",
    "cameraKeyPoints = { ## 3D\n",
    "    'imageSize': {'width': 1920, 'height': 1080},\n",
    "    'keyPoints': [\n",
    "        {\"id\": \"new-point-5\", \"x\": 797.0, \"y\": 131.0},\n",
    "        {\"id\": \"new-point-8\", \"x\": 962.0, \"y\": 129.0},\n",
    "        {\"id\": \"new-point-9\", \"x\": 964.0, \"y\": 517.0},\n",
    "        {\"id\": \"new-point-12\", \"x\": 1131.0, \"y\": 132.0},\n",
    "        {\"id\": \"new-point-29\", \"x\": 396.0, \"y\": 128.0},\n",
    "        {\"id\": \"new-point-31\", \"x\": 266.0, \"y\": 373.0},\n",
    "        {\"id\": \"new-point-33\", \"x\": 1651.0, \"y\": 374.0},\n",
    "        {\"id\": \"new-point-35\", \"x\": 1520.0, \"y\": 128.0},\n",
    "        {\"id\": \"new-point-40\", \"x\": 1180.0, \"y\": 514.0},\n",
    "        {\"id\": \"new-point-42\", \"x\": 746.0, \"y\": 512.0},\n",
    "        {\"id\": \"new-point-43\", \"x\": 563.0, \"y\": 301.0},\n",
    "        {\"id\": \"new-point-44\", \"x\": 749.0, \"y\": 232.0},\n",
    "        {\"id\": \"new-point-46\", \"x\": 739.0, \"y\": 372.0},\n",
    "        {\"id\": \"new-point-47\", \"x\": 1370.0, \"y\": 300.0},\n",
    "        {\"id\": \"new-point-48\", \"x\": 1178.0, \"y\": 230.0},\n",
    "        {\"id\": \"new-point-49\", \"x\": 1182.0, \"y\": 373.0},\n",
    "        {\"id\": \"new-point-50\", \"x\": 324.0, \"y\": 403.0},\n",
    "        {\"id\": \"new-point-51\", \"x\": 359.0, \"y\": 513.0},\n",
    "        {\"id\": \"new-point-52\", \"x\": 1604.0, \"y\": 401.0},\n",
    "        {\"id\": \"new-point-53\", \"x\": 1552.0, \"y\": 512.0}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_coordinate_transformer(camera_points, aerial_points, debug=False):\n",
    "    \"\"\"\n",
    "    Creates a function that transforms coordinates from camera view to aerial view\n",
    "    using homography with all available corresponding points.\n",
    "    \n",
    "    Args:\n",
    "        camera_points (dict): Dictionary containing camera view keypoints\n",
    "        aerial_points (dict): Dictionary containing aerial view keypoints\n",
    "        debug (bool): If True, prints debug information\n",
    "    \"\"\"\n",
    "    # Create lists to store corresponding points\n",
    "    src_points = []  # Camera view points\n",
    "    dst_points = []  # Aerial view points\n",
    "    \n",
    "    # Create mapping of IDs to aerial points for quick lookup\n",
    "    aerial_dict = {point['id']: (point['x'], point['y']) \n",
    "                  for point in aerial_points['keyPoints']}\n",
    "    \n",
    "    # Match all corresponding points between views\n",
    "    for camera_point in camera_points['keyPoints']:\n",
    "        point_id = camera_point['id']\n",
    "        if point_id in aerial_dict:\n",
    "            src_points.append([camera_point['x'], camera_point['y']])\n",
    "            dst_points.append([aerial_dict[point_id][0], aerial_dict[point_id][1]])\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    src_points = np.array(src_points, dtype=np.float32)\n",
    "    dst_points = np.array(dst_points, dtype=np.float32)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Using {len(src_points)} corresponding points for homography\")\n",
    "        print(\"\\nSource points (camera):\")\n",
    "        for i, point in enumerate(src_points):\n",
    "            print(f\"Point {i+1}: ({point[0]:.1f}, {point[1]:.1f})\")\n",
    "        print(\"\\nDestination points (aerial):\")\n",
    "        for i, point in enumerate(dst_points):\n",
    "            print(f\"Point {i+1}: ({point[0]:.1f}, {point[1]:.1f})\")\n",
    "    \n",
    "    # Calculate homography matrix\n",
    "    homography_matrix, mask = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5.0)\n",
    "    \n",
    "    if debug:\n",
    "        # Print which points were considered inliers (mask == 1)\n",
    "        inliers = np.sum(mask)\n",
    "        print(f\"\\nRANSAC found {inliers} inliers out of {len(src_points)} points\")\n",
    "    \n",
    "    def transform_coordinate(x, y):\n",
    "        \"\"\"\n",
    "        Transform a single coordinate from camera view to aerial view.\n",
    "        \n",
    "        Args:\n",
    "            x (float): x coordinate in camera view\n",
    "            y (float): y coordinate in camera view\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (x, y) coordinates in aerial view\n",
    "        \"\"\"\n",
    "        # Convert to homogeneous coordinates\n",
    "        point = np.array([[[x, y]]], dtype=np.float32)\n",
    "        \n",
    "        # Apply homography transformation\n",
    "        # We need to reshape the point to match the expected input format\n",
    "        transformed = cv2.perspectiveTransform(point, homography_matrix)\n",
    "        \n",
    "        return (float(transformed[0][0][0]), float(transformed[0][0][1]))\n",
    "    \n",
    "    return transform_coordinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Camera 3D point: (1841, 312)\n",
      "Transformed 2D point: (1734.5, 431.2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the transformer with debug info\n",
    "transformer = create_coordinate_transformer(cameraKeyPoints, aerialKeyPoints)\n",
    "\n",
    "# Test with your specific point\n",
    "test_x, test_y = 1841, 312\n",
    "transformed_x, transformed_y = transformer(test_x, test_y)\n",
    "print(f\"\\Camera 3D point: ({test_x}, {test_y})\")\n",
    "print(f\"Transformed 2D point: ({transformed_x:.1f}, {transformed_y:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Load the dictionary from the tracked.txt file\n",
    "with open('/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/main/tracked.txt', 'r') as f:\n",
    "    tracked_robots = ast.literal_eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549.5, 258.5)\n"
     ]
    }
   ],
   "source": [
    "for coordinate in tracked_robots['75']:\n",
    "    print(coordinate)\n",
    "    break\n",
    "    transformed_x, transformed_y = transformer(coordinate[0], coordinate[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to aerial2D.mp4\n"
     ]
    }
   ],
   "source": [
    "# Load the background image\n",
    "background_image_path = '/Users/shravanprasanth/Coding/Robotics/Scarlett-AI/src/main/field.jpg'\n",
    "background_image = cv2.imread(background_image_path)\n",
    "\n",
    "# Define video parameters\n",
    "video_width = background_image.shape[1]  # Width of the image\n",
    "video_height = background_image.shape[0]  # Height of the image\n",
    "output_video_path = 'aerial2D.mp4'  # Path to save the video\n",
    "\n",
    "# Create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "video_writer = cv2.VideoWriter(output_video_path, fourcc, 90.0, (video_width, video_height))\n",
    "\n",
    "# Loop through the tracked robot coordinates\n",
    "for coordinate in tracked_robots['75']:\n",
    "    # Transform the coordinate\n",
    "    transformed_x, transformed_y = transformer(coordinate[0], coordinate[1])\n",
    "    \n",
    "    # Draw the point on the loaded image\n",
    "    cv2.circle(background_image, (int(transformed_x), int(transformed_y)), 5, (0, 0, 255), -1)  # Green point\n",
    "    \n",
    "    # Write the frame to the video\n",
    "    video_writer.write(background_image)\n",
    "\n",
    "# Release the video writer\n",
    "video_writer.release()\n",
    "print(f\"Video saved to {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
