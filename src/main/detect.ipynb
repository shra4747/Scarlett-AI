{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import inference\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import requests\n",
    "import supervision as sv\n",
    "from PIL.ImageFile import ImageFile\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = inference.get_model(\"robot-detection-xru6m/8\", api_key=\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "model = YOLO('/Users/shravanprasanth/Documents/AIScouter/src/models/y8v7.pt')\n",
    "results = model.predict(source='/Users/shravanprasanth/Documents/AIScouter/src/images/test.png', conf=.35,)\n",
    "image = results[0].orig_img\n",
    "\n",
    "# Draw the bounding boxes on the image\n",
    "annotated_image = results[0].plot()\n",
    "\n",
    "# Specify the save directory\n",
    "save_dir = '/Users/shravanprasanth/Documents/AIScouter/src/runs/detect/predict'\n",
    "\n",
    "save_path = os.path.join(save_dir, 'test.png')\n",
    "cv2.imwrite(save_path, annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"/Users/shravanprasanth/Documents/AIScouter/src/images/test.png\")\n",
    "enhancer = ImageEnhance.Sharpness(image)\n",
    "sharpened_image = enhancer.enhance(2.0)  # Increase sharpness, 2.0 is an example value\n",
    "\n",
    "# Enhance Contrast\n",
    "enhancer = ImageEnhance.Contrast(sharpened_image)\n",
    "contrast_image = enhancer.enhance(1.5)  # Increase contrast, 1.5 is an example value\n",
    "\n",
    "# Enhance Brightness\n",
    "enhancer = ImageEnhance.Brightness(contrast_image)\n",
    "bright_image = enhancer.enhance(1.2)  # Increase brightness, 1.2 is an example value\n",
    "\n",
    "# Optionally, apply a denoise filter\n",
    "final_image = bright_image.filter(ImageFilter.MedianFilter(size=3))\n",
    "# confidence and overlay hereresults = model.infer(image, confidence=0.1)[0]\n",
    "\n",
    "results = model.infer(image=final_image, confidence=0.1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = sv.Detections.from_inference(results)\n",
    "\n",
    "bounding_box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "annotated_image = bounding_box_annotator.annotate(scene=image, detections=detections)\n",
    "annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "\n",
    "sv.plot_image(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = sv.Detections.from_inference(results)\n",
    "image_cv2 = cv2.cvtColor(numpy.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "bounding_box_annotator = sv.BoxAnnotator()\n",
    "annotated_image = bounding_box_annotator.annotate(scene=image_cv2, detections=detections)\n",
    "\n",
    "bboxes = detections.xyxy\n",
    "confidences = detections.confidence\n",
    "class_names = detections.data['class_name']\n",
    "\n",
    "for bbox, confidence, class_name in zip(bboxes, confidences, class_names):\n",
    "    bbox = bbox.astype(int)\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    label = f\"{class_name} ({confidence:.2f})\"\n",
    "    \n",
    "    cv2.rectangle(annotated_image, (x0, y0), (x1, y1), color=(0, 0, 0), thickness=3)\n",
    "    cv2.putText(annotated_image, label, (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 2)\n",
    "\n",
    "annotated_image_pil = Image.fromarray(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "annotated_image_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(source='/Users/shravanprasanth/Documents/AIScouter/src/images/test.png', conf=.35, save_crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('/Users/shravanprasanth/Documents/AIScouter/src/models/y8v7.pt')\n",
    "video_path = \"/Users/shravanprasanth/Documents/AIScouter/src/videos/dcmp58.mp4\"\n",
    "output_path = \"/Users/shravanprasanth/Documents/AIScouter/src/videos/output/dcmp58-y8v7.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "bounding_box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Finished processing all frames.\")\n",
    "        break\n",
    "    \n",
    "    if frame is None:\n",
    "        print(\"Empty frame encountered.\")\n",
    "        continue\n",
    "    \n",
    "    # Convert the frame from BGR (OpenCV) to RGB (PIL)\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Perform inference\n",
    "    results = model.predict(source=image_pil, conf=.35)\n",
    "    image = results[0].orig_img\n",
    "    annotated_image = results[0].plot()\n",
    "    out.write(annotated_image)\n",
    "    \n",
    "    frame_count += 1\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Video processing complete. Output saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
